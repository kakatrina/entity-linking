{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import pickle \n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators  ...   \n",
       "2       lowercase        marched      VBP  lowercase           have  ...   \n",
       "3       lowercase        through      VBN  lowercase        marched  ...   \n",
       "4     capitalized         London       IN  lowercase        through  ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ner.csv', encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n",
    "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
    "       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n",
    "       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n",
    "       'prev-prev-word', 'prev-shape', 'prev-word',\"pos\",'shape'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_idx    35177\n",
       "word            30172\n",
       "tag                17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>29.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>35.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>38.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>41.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>42.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049492</th>\n",
       "      <td>47894.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049529</th>\n",
       "      <td>47896.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049569</th>\n",
       "      <td>47897.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049642</th>\n",
       "      <td>47901.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050198</th>\n",
       "      <td>47928.0</td>\n",
       "      <td>police</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_idx    word tag\n",
       "657              29.0  police   O\n",
       "819              35.0  police   O\n",
       "886              38.0  police   O\n",
       "942              41.0  police   O\n",
       "969              42.0  police   O\n",
       "...               ...     ...  ..\n",
       "1049492       47894.0  police   O\n",
       "1049529       47896.0  police   O\n",
       "1049569       47897.0  police   O\n",
       "1049642       47901.0  police   O\n",
       "1050198       47928.0  police   O\n",
       "\n",
       "[1421 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.word=='police']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del idx2tag[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx['unavailable']=30173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_idx'] = data['word'].map(token2idx)\n",
    "data['tag_idx'] = data['tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence_idx, word, tag, word_idx, tag_idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['tag']=='nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data to sequential form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-059aaa2d111f>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['sentence_idx'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[6746, 3762, 28917, 24938, 9685, 2012, 589, 98...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 3, 14, 14, 14, 14, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[17868, 3762, 21244, 1769, 24219, 7500, 23716,...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...</td>\n",
       "      <td>[10192, 9685, 23873, 7500, 6909, 3762, 9422, 9...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[2041, 20494, 7500, 651, 3762, 12523, 17510, 1...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
       "      <td>[12068, 22153, 7546, 56, 7500, 10003, 3762, 75...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx                                               word  \\\n",
       "0           1.0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1           2.0  [Families, of, soldiers, killed, in, the, conf...   \n",
       "2           3.0  [They, marched, from, the, Houses, of, Parliam...   \n",
       "3           4.0  [Police, put, the, number, of, marchers, at, 1...   \n",
       "4           5.0  [The, protest, comes, on, the, eve, of, the, a...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...   \n",
       "\n",
       "                                            word_idx  \\\n",
       "0  [6746, 3762, 28917, 24938, 9685, 2012, 589, 98...   \n",
       "1  [17868, 3762, 21244, 1769, 24219, 7500, 23716,...   \n",
       "2  [10192, 9685, 23873, 7500, 6909, 3762, 9422, 9...   \n",
       "3  [2041, 20494, 7500, 651, 3762, 12523, 17510, 1...   \n",
       "4  [12068, 22153, 7546, 56, 7500, 10003, 3762, 75...   \n",
       "\n",
       "                                             tag_idx  \n",
       "0  [14, 14, 14, 14, 14, 14, 3, 14, 14, 14, 14, 14...  \n",
       "1  [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1...  \n",
       "2  [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3...  \n",
       "3  [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1...  \n",
       "4  [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#data_fillna = data.fillna(method='ffill', axis=0)\n",
    "#data_group = data_fillna.groupby(['sentence_idx'],as_index=False\n",
    "#                                )['word',  'tag', 'word_idx', 'tag_idx'].agg(lambda x: list(x))\n",
    "\n",
    "#data_group.head()\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_group.to_csv('train_tag_idx.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group=pd.read_csv('train_tag_idx.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in case the dataframe dosnt work\n",
    "from ast import literal_eval\n",
    "data_group['word_idx']=data_group['word_idx'].apply(lambda x: literal_eval(x))\n",
    "data_group['tag']=data_group['tag'].apply(lambda x: literal_eval(x))\n",
    "data_group['word']=data_group['word'].apply(lambda x: literal_eval(x))\n",
    "data_group['tag_idx']=data_group['tag_idx'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[17647, 6660, 28614, 16731, 27004, 3620, 22391...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 14, 8, 8, 8, 8, 8, 14, 8, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[210, 6660, 4126, 18493, 7427, 1803, 22780, 21...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...</td>\n",
       "      <td>[2783, 27004, 11953, 1803, 5969, 6660, 20398, ...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 14, 15, 8, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[6004, 13327, 1803, 4676, 6660, 12970, 23395, ...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
       "      <td>[2064, 7783, 4679, 22309, 1803, 1167, 6660, 18...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 14, 8, 8, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35172</th>\n",
       "      <td>47955.0</td>\n",
       "      <td>[Indian, border, security, forces, are, accusi...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, B-gpe, O, O, O, O, O...</td>\n",
       "      <td>[9458, 6100, 25754, 10272, 13330, 16846, 10511...</td>\n",
       "      <td>[5, 8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35173</th>\n",
       "      <td>47956.0</td>\n",
       "      <td>[Indian, officials, said, no, one, was, injure...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, B-tim, O, O, O, O...</td>\n",
       "      <td>[9458, 11940, 20929, 9758, 26786, 29656, 3338,...</td>\n",
       "      <td>[5, 8, 8, 8, 8, 8, 8, 8, 13, 8, 8, 8, 8, 8, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35174</th>\n",
       "      <td>47957.0</td>\n",
       "      <td>[Two, more, landed, in, fields, belonging, to,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[22684, 782, 9877, 7427, 11369, 7482, 4883, 17...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35175</th>\n",
       "      <td>47958.0</td>\n",
       "      <td>[They, say, not, all, of, the, rockets, explod...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[2783, 2827, 28157, 7428, 6660, 1803, 25008, 2...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35176</th>\n",
       "      <td>47959.0</td>\n",
       "      <td>[Indian, forces, said, they, responded, to, th...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O]</td>\n",
       "      <td>[9458, 10272, 20929, 13601, 25243, 4883, 1803,...</td>\n",
       "      <td>[5, 8, 8, 8, 8, 8, 8, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35177 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_idx                                               word  \\\n",
       "0               1.0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1               2.0  [Families, of, soldiers, killed, in, the, conf...   \n",
       "2               3.0  [They, marched, from, the, Houses, of, Parliam...   \n",
       "3               4.0  [Police, put, the, number, of, marchers, at, 1...   \n",
       "4               5.0  [The, protest, comes, on, the, eve, of, the, a...   \n",
       "...             ...                                                ...   \n",
       "35172       47955.0  [Indian, border, security, forces, are, accusi...   \n",
       "35173       47956.0  [Indian, officials, said, no, one, was, injure...   \n",
       "35174       47957.0  [Two, more, landed, in, fields, belonging, to,...   \n",
       "35175       47958.0  [They, say, not, all, of, the, rockets, explod...   \n",
       "35176       47959.0  [Indian, forces, said, they, responded, to, th...   \n",
       "\n",
       "                                                     tag  \\\n",
       "0      [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo...   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...   \n",
       "...                                                  ...   \n",
       "35172  [B-gpe, O, O, O, O, O, O, B-gpe, O, O, O, O, O...   \n",
       "35173  [B-gpe, O, O, O, O, O, O, O, B-tim, O, O, O, O...   \n",
       "35174                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "35175                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "35176                       [B-gpe, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                word_idx  \\\n",
       "0      [17647, 6660, 28614, 16731, 27004, 3620, 22391...   \n",
       "1      [210, 6660, 4126, 18493, 7427, 1803, 22780, 21...   \n",
       "2      [2783, 27004, 11953, 1803, 5969, 6660, 20398, ...   \n",
       "3      [6004, 13327, 1803, 4676, 6660, 12970, 23395, ...   \n",
       "4      [2064, 7783, 4679, 22309, 1803, 1167, 6660, 18...   \n",
       "...                                                  ...   \n",
       "35172  [9458, 6100, 25754, 10272, 13330, 16846, 10511...   \n",
       "35173  [9458, 11940, 20929, 9758, 26786, 29656, 3338,...   \n",
       "35174  [22684, 782, 9877, 7427, 11369, 7482, 4883, 17...   \n",
       "35175  [2783, 2827, 28157, 7428, 6660, 1803, 25008, 2...   \n",
       "35176  [9458, 10272, 20929, 13601, 25243, 4883, 1803,...   \n",
       "\n",
       "                                                 tag_idx  \n",
       "0      [8, 8, 8, 8, 8, 8, 14, 8, 8, 8, 8, 8, 14, 8, 8...  \n",
       "1      [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "2      [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 14, 15, 8, 8...  \n",
       "3      [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "4      [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 14, 8, 8, 6,...  \n",
       "...                                                  ...  \n",
       "35172  [5, 8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "35173  [5, 8, 8, 8, 8, 8, 8, 8, 13, 8, 8, 8, 8, 8, 8,...  \n",
       "35174                  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]  \n",
       "35175                  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]  \n",
       "35176                           [5, 8, 8, 8, 8, 8, 8, 8]  \n",
       "\n",
       "[35177 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out data (for later retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test=['O']\n",
    "L=[]\n",
    "m=[]\n",
    "for i in data_group['tag']:\n",
    "    for j in i:\n",
    "        if all(j)=='O':\n",
    "            L.append(i)\n",
    "        else:\n",
    "            m.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=data_group['tag'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(set(a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in a:\n",
    "    l=len((set(i)))\n",
    "    if l>1:\n",
    "        L.append(i)\n",
    "    else:\n",
    "        m.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group=pd.read_csv('train_tag_idx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embbedding weight for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[j for i in data_group['word'].to_list() for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050795"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(set([i for i in tokens]))\n",
    "word2idx = {w: i for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(word2idx,open('word2idx.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30172"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=max([len(s)for s in data_group['word'].to_list()])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random matrix for word not in word2vec corpora\n",
    "vec=[]\n",
    "\n",
    "def getitem():\n",
    "    new_vec = np.array([random.random() for i in range(300)])\n",
    "    vec.append(new_vec)\n",
    "    return new_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix1=np.zeros((len(word2idx) + 2,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30172"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(model):\n",
    "    for word, v in word2idx.items():\n",
    "        embedding_matrix1[-1]=getitem()\n",
    "        if word in model.wv.vocab:\n",
    "            embedding_matrix1[v]=model[word]\n",
    "        else:\n",
    "            embedding_matrix1[v]=getitem()\n",
    "            \n",
    "    return embedding_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-61b0393e10ca>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if word in model.wv.vocab:\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix1=matrix(word2vec_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30173"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix1[30173]=getitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 31659 \n",
      "test_tokens length: 3518 \n",
      "train_tags: 31659 \n",
      "test_tags: 3518\n"
     ]
    }
   ],
   "source": [
    "def get_pad_train_test_val(data_group, data):\n",
    "    n_token = len(list(set(data['word'].to_list())))\n",
    "    n_tag = len(list(set(data['tag'].to_list())))\n",
    "    \n",
    "    tokens = data_group['word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value=n_token-1)\n",
    "    \n",
    "    tags = data_group['tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    \n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    \n",
    "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntrain_tags:', len(train_tags),\n",
    "        '\\ntest_tags:', len(test_tags)\n",
    "    )\n",
    "    \n",
    "    return train_tokens, test_tokens, train_tags, test_tags\n",
    "\n",
    "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test_val(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  30174 \n",
      "output_dim:  300 \n",
      "input_length:  140 \n",
      "n_tags:  18\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['word'].to_list())))+1\n",
    "output_dim = 300\n",
    "input_length =140\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 300)          9052200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 140, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 140, 300)          1081200   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 140, 18)           5418      \n",
      "=================================================================\n",
      "Total params: 11,581,218\n",
      "Trainable params: 11,581,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add Embedding layer\n",
    "model.add(Embedding(input_dim=input_dim, output_dim=output_dim,weights=[embedding_matrix1], input_length=input_length))\n",
    "\n",
    "# Add bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    " # Add LSTM\n",
    "model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "# Add timeDistributed Layer\n",
    "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "#Optimiser \n",
    "adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "26/26 [==============================] - 1382s 53s/step - loss: 0.1913 - accuracy: 0.9672 - val_loss: 0.1630 - val_accuracy: 0.9676\n",
      "Epoch 2/15\n",
      "26/26 [==============================] - 1426s 55s/step - loss: 0.1611 - accuracy: 0.9672 - val_loss: 0.1539 - val_accuracy: 0.9676\n",
      "Epoch 3/15\n",
      "26/26 [==============================] - 1446s 56s/step - loss: 0.1496 - accuracy: 0.9672 - val_loss: 0.1349 - val_accuracy: 0.9676\n",
      "Epoch 4/15\n",
      "26/26 [==============================] - 1457s 56s/step - loss: 0.1212 - accuracy: 0.9679 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
      "Epoch 5/15\n",
      "26/26 [==============================] - 1462s 56s/step - loss: 0.0894 - accuracy: 0.9738 - val_loss: 0.0778 - val_accuracy: 0.9765\n",
      "Epoch 6/15\n",
      "26/26 [==============================] - 1490s 57s/step - loss: 0.0744 - accuracy: 0.9769 - val_loss: 0.0695 - val_accuracy: 0.9779\n",
      "Epoch 7/15\n",
      "26/26 [==============================] - 1453s 56s/step - loss: 0.0665 - accuracy: 0.9788 - val_loss: 0.0638 - val_accuracy: 0.9800\n",
      "Epoch 8/15\n",
      "26/26 [==============================] - 1478s 57s/step - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.0575 - val_accuracy: 0.9832\n",
      "Epoch 9/15\n",
      "26/26 [==============================] - 1510s 58s/step - loss: 0.0517 - accuracy: 0.9845 - val_loss: 0.0498 - val_accuracy: 0.9858\n",
      "Epoch 10/15\n",
      "26/26 [==============================] - 1467s 56s/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.0428 - val_accuracy: 0.9881\n",
      "Epoch 11/15\n",
      "26/26 [==============================] - 1460s 56s/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.0379 - val_accuracy: 0.9896\n",
      "Epoch 12/15\n",
      "26/26 [==============================] - 1485s 57s/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
      "Epoch 13/15\n",
      "26/26 [==============================] - 1466s 56s/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0328 - val_accuracy: 0.9912\n",
      "Epoch 14/15\n",
      "26/26 [==============================] - 1553s 60s/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0313 - val_accuracy: 0.9914\n",
      "Epoch 15/15\n",
      "26/26 [==============================] - 1629s 63s/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0312 - val_accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_tokens, np.array(train_tags), batch_size=1000, verbose=1, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yueyu\\anaconda3_new\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\yueyu\\anaconda3_new\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: bi-lstm-v3\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('bi-lstm-v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\yueyu\\anaconda3_new\\lib\\site-packages (from seqeval) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\yueyu\\anaconda3_new\\lib\\site-packages (from seqeval) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\yueyu\\anaconda3_new\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yueyu\\anaconda3_new\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yueyu\\anaconda3_new\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16176 sha256=998a1f7b4a8bfc96729fabb9115d3fc72510db73aa629d5e534a635e8e2fa6ee\n",
      "  Stored in directory: c:\\users\\yueyu\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report,precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx=pickle.load(open('tag2idx_v3.pickle','rb'))\n",
    "tag_ind=[]\n",
    "tags=[]\n",
    "for i,v in tag2idx.items():\n",
    "    tags.append(i)\n",
    "    tag_ind.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=[list(to_categorical(i, num_classes=18)) for i in tag_ind]\n",
    "tags_nd=dict(zip(tags,ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx2tag={}\n",
    "for k,v in tag2idx.items():\n",
    "    idx2tag[v]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag[0]='O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'I-eve',\n",
       " 2: 'B-art',\n",
       " 3: 'I-tim',\n",
       " 4: 'I-per',\n",
       " 5: 'B-gpe',\n",
       " 6: 'B-org',\n",
       " 7: 'I-art',\n",
       " 8: 'O',\n",
       " 9: 'I-org',\n",
       " 10: 'I-gpe',\n",
       " 11: 'B-eve',\n",
       " 12: 'I-nat',\n",
       " 13: 'B-tim',\n",
       " 14: 'B-geo',\n",
       " 15: 'I-geo',\n",
       " 16: 'B-per',\n",
       " 17: 'B-nat'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yueyu\\anaconda3_new\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        30\n",
      "         eve       0.00      0.00      0.00        32\n",
      "         geo       0.80      0.88      0.84      3829\n",
      "         gpe       0.93      0.91      0.92      1712\n",
      "         nat       0.00      0.00      0.00        21\n",
      "         org       0.22      0.59      0.32      2004\n",
      "         per       0.68      0.61      0.65      1698\n",
      "         tim       0.83      0.82      0.82      2016\n",
      "\n",
      "   micro avg       0.60      0.78      0.67     11342\n",
      "   macro avg       0.43      0.48      0.44     11342\n",
      "weighted avg       0.70      0.78      0.72     11342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for i in pred:\n",
    "        out_i = []\n",
    "        for p in i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "def test2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            for k,v in tags_nd.items():\n",
    "                if v==list(p):\n",
    "                    out_i.append(idx2tag[k])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = test2label(test_tags)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
